---
title: "Loan Prediction"
author: "Cormac Nolan"
date: "3 March 2018"
output: html_document
editor_options: 
  chunk_output_type: console
---


## Setup {.tabset}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=TRUE, error=TRUE)

set.seed(413)
```


```{r packages_and_data, warning=FALSE}
library(tidyverse)
library(caret)
library(knitr)
library(ROCR)
loan_raw <- read_csv("./data/loan_prediction/train.csv") 
loan_test_raw <- read_csv("./data/loan_prediction/test.csv") 

```

```{r functions}
clean_loan_data <- function(raw){
  raw %>% 
    mutate(Gender = replace(Gender, Gender == "", NA),
           Married = replace(Married, Married == "", NA) %>% as.character(),
           Self_Employed = replace(Self_Employed, 
                                   Self_Employed == "", NA) %>%
             as.character(),
           Loan_Amount_Term = Loan_Amount_Term %>% factor(ordered = TRUE),
           Credit_History = as.character(Credit_History),
           Credit_History = 
             replace(Credit_History, Credit_History == "1", "Y"),
           Credit_History = 
             replace(Credit_History, Credit_History == "0", "N")) %>% 
     mutate_at(c(2,3,4,5,6,11,12), as.factor)
}

```

### Explore & Clean
Our first look at the data shows a few missing values spread thinly across quite a few variables. Might be a good candidate for imputation.

Here we replace any missing values with NA and change any obviously Boolean variables to R logical.
```{r explore & clean 1}

loan_clean <- clean_loan_data(loan_raw) %>% 
  mutate(Loan_Status = as.factor(Loan_Status))

test_clean <- clean_loan_data(loan_test_raw)

loan_clean %>% is.na() %>% table()

```

A quick scatter-plot matrix shows there might be a correlation between applicant's income and their loan amount, possibly a similar but weaker effect for co-applicant's income.
```{r explore & clean 2}
loan_clean %>% select_if(is.numeric) %>% pairs()

```

Scaling before doing a density plot shows a seemingly skewed distribution with a tail to the right. These will likely need normalising before modelling. 
```{r explore & clean 3}
loan_clean %>% select_if(is.numeric) %>% 
  scale() %>% as.data.frame() %>% 
  gather() %>% 
  ggplot(aes(value, colour = key)) +
  geom_density() +
  facet_wrap(~key) +
  theme_minimal() +
  theme(legend.position = "none")

```

### Modelling
Can't seem to find any highly correlated variables. Should be ok to proceed with them as is.
```{r preprocessing 1}

cor(loan_clean %>% select_if(is.numeric)) %>% summary()
findCorrelation(cor(loan_clean %>% select_if(is.numeric)), cutoff = 0.75)

```

We need to normalise the numeric variables.
```{r preprocessing 2}
pre_proc_clean <- preProcess(loan_clean, method = c("center", "scale"))
loan_clean_preproc <-predict(pre_proc_clean, loan_clean)
```

### Modelling
```{r train control}
control <- trainControl(method = "repeatedcv", number = 10, repeats = 10)
```

```{r training}
loan_clean_fit <-
  train(Loan_Status ~ Credit_History + Property_Area, 
        data = ((loan_clean_preproc %>%
                  select(-Loan_ID) %>% na.omit %>% data.frame)
                ),
        method="glm", family="binomial", trControl=control,
        na.action = na.pass)

loan_clean_dumb_fit <- 
  glm(Loan_Status ~ Credit_History + Property_Area,
      data = ((loan_clean_preproc %>%
                  select(-Loan_ID) %>% na.omit %>% data.frame)
                ),
      family = "binomial")

```

### Model Assessment

```{r assessment 1}

loan_clean_fit$finalModel %>% summary()

varImp(loan_clean_dumb_fit)
varImp(loan_clean_fit)


```

```{r}
loan_clean$dumb_pred <-
  predict(loan_clean_dumb_fit, 
        loan_clean,
        type = "response")

loan_clean <-
  loan_clean %>% 
  mutate(dumb_pred_class = ifelse(dumb_pred > 0.5, "Y", "N"))

rocr_pred_dumb_fit <- prediction(loan_clean$dumb_pred,
                                 loan_clean$Loan_Status)

rocr_perf_dumb_fit <- performance(rocr_pred_dumb_fit,
                                  "tpr", "fpr")
dumb_auc <- performance(rocr_pred_dumb_fit, "auc")@y.values[[1]]

ggplot(data = tibble(fpr = rocr_perf_dumb_fit@x.values[[1]],
                     tpr = rocr_perf_dumb_fit@y.values[[1]]),
       aes(fpr, tpr, group = 1)) +
  geom_line(size = 1) +
  theme_minimal() +
  geom_abline(intercept = 0, slope = 1, linetype = 2) +
  annotate("text", x = 0.75, y = 0.25, label = paste("AUC =", dumb_auc))
```

Good at predicting "N", worse at predicting "Y". Don't know what's more valuable to the user here but could be worth trading off the FPR and FNR a bit if required.
```{r}

caret::confusionMatrix(loan_clean$dumb_pred_class,
                                 loan_clean$Loan_Status)
```


